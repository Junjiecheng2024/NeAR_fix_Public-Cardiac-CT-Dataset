LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name          | Type                      | Params | Mode
--------------------------------------------------------------------
0 | model         | EmbeddingDecoderShapeOnly | 1.1 M  | train
1 | focal_loss_fn | FocalLoss                 | 0      | train
--------------------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.422     Total estimated model params size (MB)
66        Modules in train mode
0         Modules in eval mode
Epoch 0:   0%|                                                                             | 0/499 [00:00<?, ?it/s]
/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/repairing/near_repairing/stage1_coronary/train_coronary_pl.py", line 199, in <module>
    main(args)
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/repairing/near_repairing/stage1_coronary/train_coronary_pl.py", line 187, in main
    trainer.fit(pl_module, train_dataloaders=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 185, in run
    closure()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/repairing/near_repairing/stage1_coronary/lightning_module.py", line 135, in training_step
    pred_logit_shape, encoded = self(indices, grids)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/repairing/near_repairing/stage1_coronary/lightning_module.py", line 116, in forward
    return self.model(indices, grids)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/near/models/nn3d/model_shape_only.py", line 195, in forward
    _, out = self.decoder(encoded, grid)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/near/models/nn3d/model_shape_only.py", line 152, in forward
    h2 = self.fc2(h1)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/modules/normalization.py", line 325, in forward
    return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/nn/functional.py", line 2956, in group_norm
    return torch.group_norm(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 31.74 GiB of which 321.62 MiB is free. Including non-PyTorch memory, this process has 31.42 GiB memory in use. Of the allocated memory 26.44 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
