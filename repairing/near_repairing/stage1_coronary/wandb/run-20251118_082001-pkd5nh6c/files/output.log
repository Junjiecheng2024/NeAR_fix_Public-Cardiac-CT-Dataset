LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name          | Type                      | Params | Mode
--------------------------------------------------------------------
0 | model         | EmbeddingDecoderShapeOnly | 1.1 M  | train
1 | focal_loss_fn | FocalLoss                 | 0      | train
--------------------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.422     Total estimated model params size (MB)
66        Modules in train mode
0         Modules in eval mode
Sanity Checking: |                                                                       | 0/? [00:00<?, ?it/s]
/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/repairing/near_repairing/stage1_coronary/train_coronary_pl.py", line 216, in <module>
    main(args)
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/repairing/near_repairing/stage1_coronary/train_coronary_pl.py", line 206, in main
    trainer.fit(pl_module, train_dataloaders=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run_stage
    self._run_sanity_check()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1082, in _run_sanity_check
    val_loop.run()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 138, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 134, in __next__
    batch = super().__next__()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 61, in __next__
    batch = next(self.iterator)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 142, in __next__
    out = next(self.iterators[0])
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 732, in __next__
    data = self._next_data()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1506, in _next_data
    return self._process_data(data, worker_id)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1541, in _process_data
    data.reraise()
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/_utils.py", line 769, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/repairing/near_repairing/stage1_coronary/train_coronary_pl.py", line 57, in __getitem__
    _, grids, labels = self.gather_fn(shape)
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/near/models/nn3d/grid.py", line 197, in __call__
    volumes = to_var(volumes)
  File "/projappl/project_2016517/chengjun/NeAR_fix_Public-Cardiac-CT-Dataset/near/utils/misc.py", line 26, in to_var
    x = x.cuda(gpu)
  File "/projappl/project_2016517/chengjun/junjieenv/lib/python3.10/site-packages/torch/cuda/__init__.py", line 398, in _lazy_init
    raise RuntimeError(
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
